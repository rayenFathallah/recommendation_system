{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a102f8c0-c72c-4ddd-83a1-9e945e0b459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5527a098-71fa-4a2b-9ce6-d9166f049391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rayen\\Desktop\\programming\\big_data\\torch_env\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "392901e8-2de0-4519-a3d9-923f7ae1432c",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_PYTHON'] = r'C:\\Users\\rayen\\Desktop\\programming\\big_data\\torch_env\\Scripts\\python.exe'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = r'C:\\Users\\rayen\\Desktop\\programming\\big_data\\torch_env\\Scripts\\python.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ab0444-1bea-494e-98b3-86b83cd7b7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea829fe0-bb27-4d31-9db4-a299882414d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connection() : \n",
    "    mongo_uri = \"mongodb://localhost:27017\"\n",
    "    client = MongoClient(mongo_uri)\n",
    "    return client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc5a822f-5bcf-45ab-9939-d9d58cff37a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = get_connection() \n",
    "db = client[\"jobs_profiles_db\"] \n",
    "jobs_collection = db['jobs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "009ae7f0-47e7-428f-bfdd-32d28d543ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_collection = db['profiles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86019831-5e62-4bc7-83e2-48e7b3dd6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles = profiles_collection.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b578e67d-f6f6-462e-bdf5-bff01fee79c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = jobs_collection.find({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6065d74-9ff8-47fa-a06d-5c6efc1adc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "897e54d1-befd-4600-9490-35f90852be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_profiles = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a93c40f-99fd-4d28-9700-376be665217d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in jobs_collection.find({}):\n",
    "  data.append(document)\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c9d89d71-2086-4186-94b7-bbfe2e02e4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_name       2872\n",
       "reference          2872\n",
       "date                  0\n",
       "location           1367\n",
       "experience          655\n",
       "education           862\n",
       "description           0\n",
       "url                   0\n",
       "website               0\n",
       "description_eng    2872\n",
       "skills                0\n",
       "topic                 0\n",
       "title              1160\n",
       "company            1160\n",
       "languages          1908\n",
       "niveau              862\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8afa5331-1178-4cb1-9c2e-97d84b3cf75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for document in profiles_collection.find({}):\n",
    "  data_profiles.append(document)\n",
    "profiles_df = pd.DataFrame(data_profiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfd8e2fa-74ef-4cfb-9a91-9f17a5535088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import findspark\n",
    "findspark.init()\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ContentBasedFiltering\") \\\n",
    "    .config(\"spark.pyspark.python\", r\"C:\\Users\\rayen\\Desktop\\programming\\big_data\\torch_env\\Scripts\\python.exe\") \\\n",
    "    .config(\"spark.pyspark.driver.python\", r\"C:\\Users\\rayen\\Desktop\\programming\\big_data\\torch_env\\Scripts\\python.exe\") \\\n",
    "     .config(\"spark.memory.offHeap.enabled\",\"true\") \\\n",
    "     .config(\"spark.memory.offHeap.size\",\"10g\") \\\n",
    "    .getOrCreate()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb167ade-b52b-4aa7-88c1-719b94b226e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop('_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd93d28e-f67a-4cf5-95b9-17d8cdc84d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df = profiles_df.drop('_id',axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce031508-85a5-4d67-a2fe-72c4bdeabeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "91528e2b-2319-4556-8b89-ec68bff3e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "profiles_df_spark =spark.createDataFrame(profiles_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "543f7477-a5d9-49c3-a7bf-d8c7cd9352e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- positions: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- educations: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- accomplishments: array (nullable = true)\n",
      " |    |-- element: map (containsNull = true)\n",
      " |    |    |-- key: string\n",
      " |    |    |-- value: string (valueContainsNull = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- days_experience: long (nullable = true)\n",
      " |-- summary: string (nullable = true)\n",
      " |-- max_level: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "profiles_df_spark.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b08706d-4a55-4221-b963-0e0aa3c5ae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- company_name: string (nullable = true)\n",
      " |-- reference: double (nullable = true)\n",
      " |-- date: double (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- experience: array (nullable = true)\n",
      " |    |-- element: long (containsNull = true)\n",
      " |-- education: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- website: string (nullable = true)\n",
      " |-- description_eng: string (nullable = true)\n",
      " |-- skills: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- topic: long (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- company: string (nullable = true)\n",
      " |-- languages: string (nullable = true)\n",
      " |-- niveau: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6919833-7da2-4c75-9f29-de705399ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d3a29b0-511f-4744-96bd-1d4b2c346111",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "experience_similarity = udf(experience_similarity_udf, DoubleType())\n",
    "\n",
    "# Define UDF for skills similarity\n",
    "def skills_similarity_udf(job_skills, profile_skills):\n",
    "    job_skills_set = set(job_skills)\n",
    "    profile_skills_set = set(profile_skills)\n",
    "    \n",
    "    # Initialize an empty list to store matched skills\n",
    "    matched_skills = []\n",
    "    \n",
    "    # Iterate over each skill in the profile\n",
    "    for profile_skill in profile_skills_set:\n",
    "        # Check if the profile skill is contained in any job skill\n",
    "        for job_skill in job_skills_set:\n",
    "            if profile_skill in job_skill:\n",
    "                # If found, add the job skill to the list of matched skills\n",
    "                matched_skills.append(job_skill)\n",
    "                break  # Break the loop as we found a match for the profile skill\n",
    "    \n",
    "    if not matched_skills:\n",
    "        return 0.0\n",
    "    \n",
    "    # Convert the list of matched skills to a set for unique values\n",
    "    matched_skills_set = set(matched_skills)\n",
    "    \n",
    "    # Create binary vectors representing matched skills\n",
    "    job_skill_vector = np.array([1 if skill in job_skills_set else 0 for skill in job_skills_set])\n",
    "    profile_skill_vector = np.array([1 if skill in matched_skills_set else 0 for skill in job_skills_set])\n",
    "    \n",
    "    # Reshape vectors for cosine similarity calculation\n",
    "    job_skill_vector = job_skill_vector.reshape(1, -1)\n",
    "    profile_skill_vector = profile_skill_vector.reshape(1, -1)\n",
    "    \n",
    "    # Compute cosine similarity between profile and job skills\n",
    "    similarity = cosine_similarity(job_skill_vector, profile_skill_vector)[0][0]\n",
    "    \n",
    "    return float(similarity)\n",
    "\n",
    "\n",
    "skills_similarity = udf(skills_similarity_udf, DoubleType())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64c02bd3-5e54-4103-bf1f-17930c763d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_broadcasted = spark.sparkContext.broadcast(profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f57c50-f0e4-4206-b4b5-e1bd33eab43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, lit, avg as spark_avg\n",
    "\n",
    "\n",
    "profile_data = {\"skills\": [\"python\", \"sql\"], \"max_level\": \"master\", \"location\": \"tunis\"}\n",
    "\n",
    "job_df = spark_df\n",
    "profile_df = spark.createDataFrame([profile_data])\n",
    "\n",
    "def skills_similarity(job_skills, profile_skills):\n",
    "    common_skills = set(job_skills) & set(profile_skills)\n",
    "    return len(common_skills) / len(job_skills)\n",
    "\n",
    "job_df_with_similarity = job_df.withColumn(\n",
    "    \"skills_similarity\", skills_similarity(col(\"skills\"), lit(profile_data[\"skills\"]))\n",
    ").withColumn(\n",
    "    \"education_similarity\", level_similarity_udf(col(\"level\"), lit(profile_data[\"max_level\"]))\n",
    ").withColumn(\n",
    "    \"location_similarity\", location_similarity_udf(col(\"location\"), lit(profile_data[\"location\"]))\n",
    ")\n",
    "\n",
    "# Calculate overall similarity (average of individual similarities)\n",
    "job_df_with_similarity = job_df_with_similarity.withColumn(\n",
    "    \"overall_similarity\", spark_avg(\n",
    "        col(\"skills_similarity\"),\n",
    "        col(\"education_similarity\"),\n",
    "        col(\"location_similarity\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the result\n",
    "job_df_with_similarity.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba3ea4-5237-4e6a-8bd2-c6432aad448a",
   "metadata": {},
   "source": [
    "## Location similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "93a51737-75da-433e-9c57-375183da2f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "from fuzzywuzzy import fuzz\n",
    "def location_similarity(profile_loc,job_loc,threshold=90) : \n",
    "    if job_loc :\n",
    "        similarity_score = fuzz.ratio(profile_loc.lower(), job_loc.lower())\n",
    "        return float(1) if similarity_score >= threshold else float(0)\n",
    "    else:\n",
    "        return float(1)\n",
    "\n",
    "profile_location = \"tunis\"\n",
    "threshold = 80\n",
    "location_udf = udf(lambda job_loc: location_similarity(profile_location, job_loc,threshold), FloatType())\n",
    "spark_df = spark_df.withColumn(\"location_sim\", location_udf(spark_df[\"location\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cca771-1389-462b-9627-fde1d9ae76d1",
   "metadata": {},
   "source": [
    "## Level of study similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "324bad4e-7bd2-4567-8a04-2d9b2181b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "level = 'Bac + 3' \n",
    "def level_similarity(profile_level, job_level):\n",
    "    return float(1) if profile_level == job_level else float(0)\n",
    "level_udf = udf(lambda job_level : level_similarity(level,job_level),FloatType())\n",
    "level_concat = spark_df.withColumn(\"level_sim\", level_udf(spark_df[\"niveau\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c79b0c5-57cd-4ced-8cbe-696cdf4553b5",
   "metadata": {},
   "source": [
    "## Experience similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9f36625e-447a-4ed2-b3ae-ff8222486672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience_similarity(job_exp, profile_exp):\n",
    "    profile_years = int(profile_exp / 365)\n",
    "    if not profile_years : \n",
    "        return float(0) \n",
    "    if job_exp :  \n",
    "        if job_exp[0] and job_exp[1] : \n",
    "            if job_exp[0] <= profile_years <= job_exp[1]:\n",
    "                return float(1)\n",
    "            elif profile_years > job_exp[1]:\n",
    "                return float(1.2)\n",
    "            else:\n",
    "                return float(0)\n",
    "        else : \n",
    "            return float(1)\n",
    "    else : \n",
    "        return float(1)\n",
    "profile_experience = 0\n",
    "experience_udf = udf(lambda job_experience : experience_similarity(job_experience,profile_experience),FloatType())\n",
    "experience_df = spark_df.withColumn(\"experience_sim\", experience_udf(spark_df[\"experience\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "be219549-deb7-4273-b42f-4f1da7131c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = experience_df.groupBy(\"experience_sim\").count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5d44b88e-3f7e-4c2c-9d79-324eb8d190be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|experience_sim|count|\n",
      "+--------------+-----+\n",
      "|           0.0| 4032|\n",
      "+--------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "value_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfae6c29-cb26-4c18-8abb-638f95916119",
   "metadata": {},
   "source": [
    "## Skills similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dbde3597-ef88-4afa-b8c7-b85649949aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def skills_similiarity(resume_skills, job_skills,job_description):\n",
    "    resume_skills_set = set(map(str.lower, resume_skills))\n",
    "    job_skills_set = set(map(str.lower, job_skills))\n",
    "    common_skills = resume_skills_set & job_skills_set\n",
    "    for skill in resume_skills_set.copy():\n",
    "        if skill in job_description.lower() : \n",
    "            common_skills.add(skill)\n",
    "            job_skills_set.add(skill)\n",
    "        for job_skill in job_skills_set:\n",
    "            if skill in job_skill or job_skill in skill:\n",
    "                common_skills.add(job_skill)\n",
    "    if len(job_skills_set ) : \n",
    "        return len(common_skills) / len(job_skills_set)\n",
    "    return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "71f0e818-133f-4141-8f23-1f7c4c89d4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills Similarity: 0.8\n"
     ]
    }
   ],
   "source": [
    "resume_skills = [\"Python\", \"SQL\", \"Excel\",'big data']\n",
    "job_skills = [\"Python\", \"SQL\", \"Java\", \"Python Programming\"]\n",
    "job_decription = \"\"\"Integration Objects is a global leader in industrial digital transformation solutions including: Industrial Iot (IIoT), Cybersecurity, Data Analytics, Big Data, Process Control and Automation Systems. To strengthen its team, Integration Objects is recruiting: 1- Full Project Cycle Management: Lead the project journey, from the collection of initial requirements to the meticulous definition of execution plans. 2- Progress Monitoring: Document and closely monitor the progress of the project using Key Performance Indicators (KPIs) and Success Indicators. 3- Risk Assessment and Mitigation: Conduct in-depth project risk assessments and develop effective mitigation strategies to ensure project success. 4- Communication with Stakeholders: Maintain transparent communication with all project stakeholders and ensure that their needs are met throughout the project life cycle. 5- Resource Optimization: Effectively manage project resources to maximize productivity and minimize waste. 6- Budget and Schedule Management: Continuously update and manage the project schedule and budget to maintain alignment with project objectives. : -You hold a diploma in Industrial, Automatic, Electrical, or Instrumentation Engineering, or an equivalent qualification. -You have at least 5 years of experience or more in a similar position. -Strong knowledge of PLC, DCS/SCADA systems and telecommunications development. -Experience in FAT, SAT, operational verification, automation project start-up. -Good level of French in English (oral and written) -Strong organizational skills, supported by a good spirit of analysis and synthesis, allowing a high degree of autonomy\"\"\"\n",
    "similarity = skills_similiarity(resume_skills, job_skills,job_decription)\n",
    "print(\"Skills Similarity:\", similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "88d10c4b-56f9-4a77-8f7c-eb24b4f8b581",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_skills = [\"Python\", \"SQL\", \"Java\", \"docker\",'CI CD']\n",
    "skills_udf = udf(lambda job_skills,job_description : skills_similiarity(profile_skills,job_skills,job_description),FloatType())\n",
    "skills_df = spark_df.withColumn(\"skills_sim\", skills_udf(spark_df[\"skills\"],spark_df['description']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d5f1ef1d-9e59-4fac-92a9-c312cbb6cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_values = skills_df.orderBy(desc(\"skills_sim\")).select(\"skills_sim\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1b4fb5c4-1099-4b00-a1a6-f7e281223119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|skills_sim|\n",
      "+----------+\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "|       1.0|\n",
      "| 0.6666667|\n",
      "| 0.6666667|\n",
      "| 0.6666667|\n",
      "| 0.6666667|\n",
      "| 0.6666667|\n",
      "|       0.5|\n",
      "|       0.5|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "similarity_values.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a38fad-b18a-43c6-9deb-7d9ba4396f94",
   "metadata": {},
   "source": [
    "## Overall similarity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9b363d7a-7b65-4c85-bafc-85d195de8926",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\"skills_sim\": 0.6, \"location_sim\": 0.2, \"level_sim\": 0.1, \"experience_sim\": 0.1}\n",
    "\n",
    "job_df_with_similarity = spark_df.withColumn(\n",
    "    \"level_sim\", level_udf(spark_df[\"niveau\"])\n",
    ").withColumn(\n",
    "    \"location_sim\", location_udf(spark_df[\"location\"])\n",
    ").withColumn(\n",
    "    \"experience_sim\", experience_udf(spark_df[\"experience\"])\n",
    ").withColumn(\n",
    "    \"skills_sim\", skills_udf(spark_df[\"skills\"], spark_df[\"description\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "ab81b80c-350d-40dd-9ab8-ac64f74b29bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df_with_similarity = job_df_with_similarity.withColumn(\n",
    "    \"overall_similarity\", \n",
    "    sum(col(similarity) * weights[similarity] for similarity in weights)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "849ad6e0-da18-4257-825d-1932bcf949d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|overall_similarity|\n",
      "+------------------+\n",
      "|               0.9|\n",
      "|               0.8|\n",
      "|               0.8|\n",
      "|               0.8|\n",
      "|               0.8|\n",
      "|               0.8|\n",
      "| 0.700000011920929|\n",
      "| 0.700000011920929|\n",
      "| 0.600000011920929|\n",
      "| 0.600000011920929|\n",
      "| 0.600000011920929|\n",
      "|               0.6|\n",
      "|               0.6|\n",
      "|               0.6|\n",
      "|               0.6|\n",
      "|               0.6|\n",
      "|               0.6|\n",
      "|               0.6|\n",
      "|               0.6|\n",
      "|0.5400000035762786|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_similarity_scores = job_df_with_similarity.orderBy(col(\"overall_similarity\").desc()).select(\"overall_similarity\")\n",
    "\n",
    "top_similarity_scores.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd597bf-bd65-4646-9d59-d6b0c5d4447a",
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data = {\"skills\": [\"python\", \"sql\"], \"max_level\": \"master\", \"location\": \"tunis\"}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
