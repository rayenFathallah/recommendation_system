{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7590738,"sourceType":"datasetVersion","datasetId":4418374}],"dockerImageVersionId":30715,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install yake","metadata":{"execution":{"iopub.status.busy":"2024-05-30T20:47:13.320728Z","iopub.execute_input":"2024-05-30T20:47:13.321124Z","iopub.status.idle":"2024-05-30T20:47:26.393967Z","shell.execute_reply.started":"2024-05-30T20:47:13.321090Z","shell.execute_reply":"2024-05-30T20:47:26.392546Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Collecting yake\n  Downloading yake-0.4.8-py2.py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.10/site-packages (from yake) (0.9.0)\nRequirement already satisfied: click>=6.0 in /opt/conda/lib/python3.10/site-packages (from yake) (8.1.7)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from yake) (1.26.4)\nCollecting segtok (from yake)\n  Downloading segtok-1.5.11-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from yake) (3.2.1)\nCollecting jellyfish (from yake)\n  Downloading jellyfish-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from segtok->yake) (2023.12.25)\nDownloading yake-0.4.8-py2.py3-none-any.whl (60 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.2/60.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading jellyfish-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading segtok-1.5.11-py3-none-any.whl (24 kB)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Error parsing requirements for pybind11: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/pybind11-2.12.0.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: segtok, jellyfish, yake\nSuccessfully installed jellyfish-1.0.4 segtok-1.5.11 yake-0.4.8\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import yake\n\n# Initialize the Keyword Extractor with a high number of keywords\nkw_extractor = yake.KeywordExtractor()\n\ntext = \"\"\"spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython. The library is published under the MIT license and its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\"\n\nlanguage = \"en\"\nmax_ngram_size = 3\ndeduplication_threshold = 0.3\n\n# Setting numOfKeywords to a very high value to extract as many keywords as possible\nnumOfKeywords = 1000000\n\ncustom_kw_extractor = yake.KeywordExtractor(\n    lan=language, \n    n=max_ngram_size, \n    dedupLim=deduplication_threshold, \n    top=numOfKeywords, \n    features=None\n)\n\n# Extract keywords\nkeywords = custom_kw_extractor.extract_keywords(text)\n\n# Print keywords\nfor kw in keywords:\n    print(kw)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-30T20:49:48.223744Z","iopub.execute_input":"2024-05-30T20:49:48.224166Z","iopub.status.idle":"2024-05-30T20:49:48.335945Z","shell.execute_reply.started":"2024-05-30T20:49:48.224133Z","shell.execute_reply":"2024-05-30T20:49:48.334396Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"('programming languages Python', 0.001295347548560416)\n('advanced natural language', 0.0026621455770583914)\n('open-source software library', 0.008298152696966859)\n('language processing', 0.01453240965208459)\n('software company Explosion', 0.015993140254256993)\n('Ines Montani', 0.03375876229391358)\n('Matthew Honnibal', 0.04096703831447956)\n('Honnibal and Ines', 0.04096703831447956)\n('Cython', 0.053691021027863564)\n('library for advanced', 0.07441175006256819)\n('MIT license', 0.07470171819667136)\n('developers are Matthew', 0.07470171819667136)\n('spaCy', 0.10241338875304772)\n('written', 0.10241338875304772)\n('natural', 0.13442462743719766)\n('MIT', 0.19838041526103037)\n('published', 0.35038366644254865)\n('founders', 0.35038366644254865)\n","output_type":"stream"}]},{"cell_type":"code","source":"data_analyst = \"\"\"Work closely with project managers to understand and maintain focus on their analytics needs, including critical metrics and KPIs, and deliver actionable insights to relevant decision-makers\nProactively analyze data to answer key questions for stakeholders or yourself, with an eye on what drives business performance, and investigate and communicate which areas need improvement in efficiency and productivity\nCreate and maintain rich interactive visualizations through data interpretation and analysis, with reporting components from multiple data sources\nDefine and implement data acquisition and integration logic, selecting an appropriate combination of methods and tools within the defined technology stack to ensure optimal scalability and performance of the solution\nDevelop and maintain databases by acquiring data from primary and secondary sources, and build scripts that will make our data evaluation process more flexible or scalable across datasets\nRequired skills and qualifications\nThree or more years of experience mining data as a data analyst\nProven analytics skills, including mining, evaluation, and visualization\nTechnical writing experience in relevant areas, including queries, reports, and presentations\nStrong SQL or Excel skills, with aptitude for learning other analytics tools\nPreferred skills and qualifications\nBachelor’s degree (or equivalent) in mathematics, computer science, economics, or statistics\nExperience with database and model design and segmentation techniques\nStrong programming experience with frameworks, including XML, JavaScript, and ETL\nPractical experience in statistical analysis through the use of statistical packages, including Excel, SPSS, and SAS\nProven success in a collaborative, team-oriented environment\"\"\"\nkeywords = custom_kw_extractor.extract_keywords(data_analyst)\nfor kw in keywords:\n    print(kw)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T20:51:18.396927Z","iopub.execute_input":"2024-05-30T20:51:18.397848Z","iopub.status.idle":"2024-05-30T20:51:19.313766Z","shell.execute_reply.started":"2024-05-30T20:51:18.397800Z","shell.execute_reply":"2024-05-30T20:51:19.312526Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"('deliver actionable insights', 0.006292090048676595)\n('including critical metrics', 0.012484004095825714)\n('Work closely', 0.030958821949665365)\n('metrics and KPIs', 0.030958821949665365)\n('closely with project', 0.03319217294863567)\n('project managers', 0.03319217294863567)\n('managers to understand', 0.03319217294863567)\n('data', 0.03769932949378333)\n('maintain focus', 0.05692990503400047)\n('experience', 0.0831342985593201)\n('skills', 0.10146977366076045)\n('drives business performance', 0.11726177012221216)\n('Create and maintain', 0.17872440065250605)\n('deliver', 0.17923684415336186)\n('insights', 0.17923684415336186)\n('implement data acquisition', 0.19127081578271737)\n('sources', 0.20186463848413871)\n('acquiring data', 0.22418199561561425)\n('questions for stakeholders', 0.22855019097940518)\n('qualifications', 0.23887993932907217)\n('areas', 0.24341911470038466)\n('Strong', 0.2648890667069405)\n('analysis', 0.2710999005675128)\n('statistical', 0.30020346016830396)\n('rich interactive', 0.38038208087484765)\n('components from multiple', 0.38038208087484765)\n('XML', 0.41701758100364145)\n('answer', 0.43131478185802663)\n('key', 0.43131478185802663)\n('communicate', 0.43131478185802663)\n('improvement', 0.43131478185802663)\n('defined technology stack', 0.49052540599160194)\n('ensure optimal scalability', 0.49052540599160194)\n('scalable across datasets', 0.5546519143086704)\n('logic', 0.5551627776761279)\n('Develop', 0.5875654093224696)\n('data from primary', 0.5952624978848932)\n('make', 0.6071991149269631)\n('reports', 0.6321993306068446)\n('writing', 0.6700534528717415)\n('Bachelor ’s degree', 0.836838438845647)\n('aptitude for learning', 0.8546066915355621)\n('team-oriented environment', 0.930759312834367)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This showed so much noise and verbs that are not helpful, we need more specification, so this method is not the optimal. ","metadata":{}},{"cell_type":"code","source":"!pip install rake_nltk","metadata":{"execution":{"iopub.status.busy":"2024-05-30T20:54:37.326728Z","iopub.execute_input":"2024-05-30T20:54:37.327695Z","iopub.status.idle":"2024-05-30T20:54:52.166045Z","shell.execute_reply.started":"2024-05-30T20:54:37.327604Z","shell.execute_reply":"2024-05-30T20:54:52.164755Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Collecting rake_nltk\n  Downloading rake_nltk-1.0.6-py3-none-any.whl.metadata (6.4 kB)\nCollecting nltk<4.0.0,>=3.6.2 (from rake_nltk)\n  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk<4.0.0,>=3.6.2->rake_nltk) (4.66.4)\nDownloading rake_nltk-1.0.6-py3-none-any.whl (9.1 kB)\nDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Error parsing requirements for pybind11: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/pybind11-2.12.0.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0mInstalling collected packages: nltk, rake_nltk\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.2.4\n    Uninstalling nltk-3.2.4:\n      Successfully uninstalled nltk-3.2.4\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npreprocessing 0.1.13 requires nltk==3.2.4, but you have nltk 3.8.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nltk-3.8.1 rake_nltk-1.0.6\n","output_type":"stream"}]},{"cell_type":"code","source":"from rake_nltk import Rake\nrake_nltk_var = Rake()\ntext = \"\"\"spaCy is an open-source software library for advanced natural language processing,\nwritten in the programming languages Python and Cython. The library is published under the MIT license\nand its main developers are Matthew Honnibal and Ines Montani, the founders of the software company Explosion.\"\"\"\nrake_nltk_var.extract_keywords_from_text(data_analyst)\nkeyword_extracted = rake_nltk_var.get_ranked_phrases()\nprint(keyword_extracted)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-30T20:58:07.466750Z","iopub.execute_input":"2024-05-30T20:58:07.467157Z","iopub.status.idle":"2024-05-30T20:58:07.476506Z","shell.execute_reply.started":"2024-05-30T20:58:07.467127Z","shell.execute_reply":"2024-05-30T20:58:07.475222Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"['scalable across datasets required skills', 'segmentation techniques strong programming experience', 'data analyst proven analytics skills', 'visualization technical writing experience', 'makers proactively analyze data', 'maintain rich interactive visualizations', 'analytics tools preferred skills', 'multiple data sources define', 'sas proven success', 'presentations strong sql', 'etl practical experience', 'implement data acquisition', 'experience mining data', 'ensure optimal scalability', 'deliver actionable insights', 'defined technology stack', 'answer key questions', 'qualifications bachelor ’', 'areas need improvement', 'data evaluation process', 'including critical metrics', 'drives business performance', 'excel skills', 'analytics needs', 'statistics experience', 'data interpretation', 'acquiring data', 'tools within', 'secondary sources', 'including mining', 'maintain focus', 'maintain databases', 'relevant areas', 'qualifications three', 'including xml', 'including queries', 'including excel', 'work closely', 'statistical packages', 'solution develop', 'reporting components', 'relevant decision', 'project managers', 'productivity create', 'oriented environment', 'model design', 'integration logic', 'computer science', 'build scripts', 'appropriate combination', 'statistical analysis', 'performance', 'evaluation', 'analysis', 'years', 'use', 'understand', 'team', 'stakeholders', 'spss', 'selecting', 'reports', 'primary', 'methods', 'mathematics', 'make', 'learning', 'kpis', 'javascript', 'investigate', 'frameworks', 'flexible', 'eye', 'equivalent', 'efficiency', 'economics', 'degree', 'database', 'communicate', 'collaborative', 'aptitude']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Just like the previous exmaple, so much noise introduced in this method. \n","metadata":{}},{"cell_type":"markdown","source":"## Using tf-idf","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:00:25.462060Z","iopub.execute_input":"2024-05-30T21:00:25.463072Z","iopub.status.idle":"2024-05-30T21:00:26.249832Z","shell.execute_reply.started":"2024-05-30T21:00:25.463023Z","shell.execute_reply":"2024-05-30T21:00:26.248508Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"jobs_data = pd.read_csv('/kaggle/input/1-3m-linkedin-jobs-and-skills-2024/job_skills.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:04:21.186364Z","iopub.execute_input":"2024-05-30T21:04:21.186820Z","iopub.status.idle":"2024-05-30T21:04:39.800027Z","shell.execute_reply.started":"2024-05-30T21:04:21.186786Z","shell.execute_reply":"2024-05-30T21:04:39.798646Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"jobs_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:04:39.802358Z","iopub.execute_input":"2024-05-30T21:04:39.802829Z","iopub.status.idle":"2024-05-30T21:04:39.814690Z","shell.execute_reply.started":"2024-05-30T21:04:39.802790Z","shell.execute_reply":"2024-05-30T21:04:39.813614Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"                                            job_link  \\\n0  https://www.linkedin.com/jobs/view/housekeeper...   \n1  https://www.linkedin.com/jobs/view/assistant-g...   \n2  https://www.linkedin.com/jobs/view/school-base...   \n3  https://www.linkedin.com/jobs/view/electrical-...   \n4  https://www.linkedin.com/jobs/view/electrical-...   \n\n                                          job_skills  \n0  Building Custodial Services, Cleaning, Janitor...  \n1  Customer service, Restaurant management, Food ...  \n2  Applied Behavior Analysis (ABA), Data analysis...  \n3  Electrical Engineering, Project Controls, Sche...  \n4  Electrical Assembly, Point to point wiring, St...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>job_link</th>\n      <th>job_skills</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://www.linkedin.com/jobs/view/housekeeper...</td>\n      <td>Building Custodial Services, Cleaning, Janitor...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://www.linkedin.com/jobs/view/assistant-g...</td>\n      <td>Customer service, Restaurant management, Food ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://www.linkedin.com/jobs/view/school-base...</td>\n      <td>Applied Behavior Analysis (ABA), Data analysis...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://www.linkedin.com/jobs/view/electrical-...</td>\n      <td>Electrical Engineering, Project Controls, Sche...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://www.linkedin.com/jobs/view/electrical-...</td>\n      <td>Electrical Assembly, Point to point wiring, St...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"jobs_data = jobs_data[~jobs_data['job_skills'].isna()]","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:16:12.103545Z","iopub.execute_input":"2024-05-30T21:16:12.103983Z","iopub.status.idle":"2024-05-30T21:16:12.418999Z","shell.execute_reply.started":"2024-05-30T21:16:12.103948Z","shell.execute_reply":"2024-05-30T21:16:12.417846Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"def remove_punctuation(text):\n\n    text = text.lower().strip()\n    no_punct = \"\"\n    for char in text:\n        if char.isalnum() or char == \" \":  # Check if alphanumeric or space\n            no_punct += char\n    return no_punct\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:20:54.966029Z","iopub.execute_input":"2024-05-30T21:20:54.966574Z","iopub.status.idle":"2024-05-30T21:20:54.973397Z","shell.execute_reply.started":"2024-05-30T21:20:54.966528Z","shell.execute_reply":"2024-05-30T21:20:54.972029Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"jobs_data['job_skills'] = jobs_data['job_skills'].apply(remove_punctuation)","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:20:57.160473Z","iopub.execute_input":"2024-05-30T21:20:57.160885Z","iopub.status.idle":"2024-05-30T21:22:12.969833Z","shell.execute_reply.started":"2024-05-30T21:20:57.160855Z","shell.execute_reply":"2024-05-30T21:22:12.968409Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/2928939654.py:1: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  jobs_data['job_skills'] = jobs_data['job_skills'].apply(remove_punctuation)\n","output_type":"stream"}]},{"cell_type":"code","source":"jobs = jobs_data['job_skills'].to_list()","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:22:12.972623Z","iopub.execute_input":"2024-05-30T21:22:12.973117Z","iopub.status.idle":"2024-05-30T21:22:13.022992Z","shell.execute_reply.started":"2024-05-30T21:22:12.973072Z","shell.execute_reply":"2024-05-30T21:22:13.021545Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"import sklearn\nfrom sklearn.feature_extraction.text import CountVectorizer","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:04:58.448645Z","iopub.execute_input":"2024-05-30T21:04:58.449105Z","iopub.status.idle":"2024-05-30T21:04:58.454863Z","shell.execute_reply.started":"2024-05-30T21:04:58.449073Z","shell.execute_reply":"2024-05-30T21:04:58.453461Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"!pip install nltk","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:07:17.247417Z","iopub.execute_input":"2024-05-30T21:07:17.247901Z","iopub.status.idle":"2024-05-30T21:07:29.969603Z","shell.execute_reply.started":"2024-05-30T21:07:17.247866Z","shell.execute_reply":"2024-05-30T21:07:29.968084Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.8.1)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk) (8.1.7)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk) (1.4.2)\nRequirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.10/site-packages (from nltk) (2023.12.25)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk) (4.66.4)\n\u001b[33mWARNING: Error parsing requirements for aiohttp: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/aiohttp-3.9.1.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m\u001b[33mWARNING: Error parsing requirements for pybind11: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/pybind11-2.12.0.dist-info/METADATA'\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from nltk.corpus import stopwords\nimport nltk\nnltk.download('stopwords')\n\nstopwords = list(set(stopwords.words('english')))","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:08:54.124212Z","iopub.execute_input":"2024-05-30T21:08:54.124695Z","iopub.status.idle":"2024-05-30T21:08:54.132124Z","shell.execute_reply.started":"2024-05-30T21:08:54.124660Z","shell.execute_reply":"2024-05-30T21:08:54.131013Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"vect = CountVectorizer(max_df=0.70,stop_words=stopwords,max_features=13000)\nword_count_vect = vect.fit_transform(jobs)\n\nprint(list(vect.vocabulary_.keys())[:10])","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:22:13.024586Z","iopub.execute_input":"2024-05-30T21:22:13.025114Z","iopub.status.idle":"2024-05-30T21:23:15.400043Z","shell.execute_reply.started":"2024-05-30T21:22:13.025051Z","shell.execute_reply":"2024-05-30T21:23:15.398690Z"},"trusted":true},"execution_count":78,"outputs":[{"name":"stdout","text":"['building', 'custodial', 'services', 'cleaning', 'janitorial', 'materials', 'handling', 'housekeeping', 'sanitation', 'waste']\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer\n\ndef sort_coo(coo_matrix):\n    tuples = zip(coo_matrix.col, coo_matrix.data)\n    return sorted(tuples, key=lambda x: (x[1], x[0]), reverse=True)\n\ndef extract_topn_from_vector(feature_names, sorted_items, topn=10):\n    \"\"\"get the feature names and tf-idf score of top n items\"\"\"\n    \n    #use only topn items from vector\n    sorted_items = sorted_items[:topn]\n\n    score_vals = []\n    feature_vals = []\n    \n    # word index and corresponding tf-idf score\n    for idx, score in sorted_items:\n        \n        #keep track of feature name and its corresponding score\n        score_vals.append(round(score, 3))\n        feature_vals.append(feature_names[idx])\n\n\n    results= {}\n    for idx in range(len(feature_vals)):\n        results[feature_vals[idx]]=score_vals[idx]\n    \n    return results\n \ntfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\ntfidf_transformer.fit(word_count_vect)\n\n\ntest_data = [\"\"\"We are looking for an organized,  analytical and skilled individual to join our team as a Back-end developer for our PIM & WEB projects (back-end) implementations & integrations.\n    you translate the needs and questions of the customer into practical applications\n    you build software solutions that provide significant added value\n    you are responsible for end-to-end development of applications\n    you think along to deliver optimal system archtectural solutions \n    you have experience in building and/or integrating API’s\n    you have in-depth knowledge about at least Java, JavaScript, MS SQL, jQuery, HTML, CSS\"\"\",data_analyst.lower().replace(',',' '),text.lower()]\n\n# you only needs to do this once, this is a mapping of index to \nfeature_names = vect.get_feature_names_out()\n\n#generate tf-idf for the given document\nfor elem in test_data : \n    tf_idf_vector = tfidf_transformer.transform(vect.transform([elem]))\n\n    #sort the tf-idf vectors by descending order of scores\n    sorted_items=sort_coo(tf_idf_vector.tocoo())\n\n    #extract only the top n; n here is 10\n    keywords=extract_topn_from_vector(feature_names,sorted_items,25)\n\n    # now print the results\n    print(\"\\n=====Doc=====\")\n    print(elem)\n    print(\"\\n===Keywords===\")\n    for k in keywords:\n        print(k,keywords[k])","metadata":{"execution":{"iopub.status.busy":"2024-05-30T21:25:42.673200Z","iopub.execute_input":"2024-05-30T21:25:42.673715Z","iopub.status.idle":"2024-05-30T21:25:43.001195Z","shell.execute_reply.started":"2024-05-30T21:25:42.673669Z","shell.execute_reply":"2024-05-30T21:25:42.999714Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stdout","text":"\n=====Doc=====\nWe are looking for an organized,  analytical and skilled individual to join our team as a Back-end developer for our PIM & WEB projects (back-end) implementations & integrations.\n    you translate the needs and questions of the customer into practical applications\n    you build software solutions that provide significant added value\n    you are responsible for end-to-end development of applications\n    you think along to deliver optimal system archtectural solutions \n    you have experience in building and/or integrating API’s\n    you have in-depth knowledge about at least Java, JavaScript, MS SQL, jQuery, HTML, CSS\n\n===Keywords===\nend 0.459\nback 0.271\nalong 0.192\npim 0.186\nsolutions 0.183\nadded 0.181\nintegrating 0.179\ntranslate 0.177\napplications 0.174\nsignificant 0.16\noptimal 0.16\nthink 0.157\nimplementations 0.153\njquery 0.151\nintegrations 0.146\nquestions 0.14\ndeliver 0.139\ndeveloper 0.139\nresponsible 0.135\nleast 0.13\norganized 0.123\ncss 0.122\ndepth 0.122\nprovide 0.121\nhtml 0.12\n\n=====Doc=====\nwork closely with project managers to understand and maintain focus on their analytics needs  including critical metrics and kpis  and deliver actionable insights to relevant decision-makers\nproactively analyze data to answer key questions for stakeholders or yourself  with an eye on what drives business performance  and investigate and communicate which areas need improvement in efficiency and productivity\ncreate and maintain rich interactive visualizations through data interpretation and analysis  with reporting components from multiple data sources\ndefine and implement data acquisition and integration logic  selecting an appropriate combination of methods and tools within the defined technology stack to ensure optimal scalability and performance of the solution\ndevelop and maintain databases by acquiring data from primary and secondary sources  and build scripts that will make our data evaluation process more flexible or scalable across datasets\nrequired skills and qualifications\nthree or more years of experience mining data as a data analyst\nproven analytics skills  including mining  evaluation  and visualization\ntechnical writing experience in relevant areas  including queries  reports  and presentations\nstrong sql or excel skills  with aptitude for learning other analytics tools\npreferred skills and qualifications\nbachelor’s degree (or equivalent) in mathematics  computer science  economics  or statistics\nexperience with database and model design and segmentation techniques\nstrong programming experience with frameworks  including xml  javascript  and etl\npractical experience in statistical analysis through the use of statistical packages  including excel  spss  and sas\nproven success in a collaborative  team-oriented environment\n\n===Keywords===\nincluding 0.359\ndata 0.249\nmaintain 0.191\nanalytics 0.164\nsources 0.163\nproven 0.146\nmining 0.14\nqualifications 0.14\nareas 0.138\nrelevant 0.123\nexperience 0.12\nstatistical 0.117\ninvestigate 0.109\nacquiring 0.108\nrich 0.108\nvisualizations 0.103\ndefine 0.102\nproactively 0.101\nmakers 0.101\nselecting 0.099\nanswer 0.099\nactionable 0.098\ndatasets 0.097\ncombination 0.095\nclosely 0.094\n\n=====Doc=====\nthis is a string! with some punctuation. we will remove it all.\n\n===Keywords===\nremove 0.758\npunctuation 0.653\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Since that these method does not use skills matching algorithm, it is still a poor choice and doesn't give the optimal results, even thought it was trained on skills data. ","metadata":{}},{"cell_type":"markdown","source":"At the end, the results lead to choosing the sophisticated skills_extraction method which proves to be the most accurate and less noisy among the previous results. ","metadata":{}},{"cell_type":"markdown","source":"=","metadata":{}}]}